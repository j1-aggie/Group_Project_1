{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24 24 24 24\n"
     ]
    }
   ],
   "source": [
    "#Set dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "sensors = ['42043','42044','42047','8764314','8770613', 'TABS-X']\n",
    "months = ['June 2017','July 2017','August 2017','Sept 2017']\n",
    "monthsf = ['0617','0717','0817','0917']\n",
    "\n",
    "file1 = []\n",
    "file2 = []\n",
    "file3 = []\n",
    "file4 = []\n",
    "file5 = []\n",
    "\n",
    "#naming csv file for all resources\n",
    "for i in sensors:\n",
    "    for j in months:\n",
    "        file1.append(f\"../Resources/Project Data/Dirty Trail Data/Harvey 17/{i}/{j} air_pressure.csv\")\n",
    "        file2.append(f\"../Resources/Project Data/Dirty Trail Data/Harvey 17/{i}/{j} air_temperature.csv\")\n",
    "        file3.append(f\"../Resources/Project Data/Dirty Trail Data/Harvey 17/{i}/{j} sea_water_practical_salinity.csv\")\n",
    "        file4.append(f\"../Resources/Project Data/Dirty Trail Data/Harvey 17/{i}/{j} sea_water_temperature.csv\")\n",
    "        file5.append(f\"../Resources/Project Data/Dirty Trail Data/Harvey 17/{i}/{j} winds.csv\")\n",
    "        \n",
    "print(len(file1),len(file2),len(file3),len(file4),len(file5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csvfile 0\n",
      "Reading csvfile 1\n",
      "Reading csvfile 2\n",
      "Reading csvfile 3\n",
      "Reading csvfile 4\n",
      "Reading csvfile 5\n",
      "Reading csvfile 6\n",
      "Reading csvfile 7\n",
      "Reading csvfile 8\n",
      "Reading csvfile 9\n",
      "Reading csvfile 10\n",
      "Reading csvfile 11\n",
      "Reading csvfile 12\n",
      "Reading csvfile 13\n",
      "Reading csvfile 14\n",
      "Reading csvfile 15\n",
      "Reading csvfile 16\n",
      "Reading csvfile 17\n",
      "Reading csvfile 18\n",
      "Reading csvfile 19\n",
      "Reading csvfile 20\n",
      "Reading csvfile 21\n",
      "Reading csvfile 22\n",
      "Reading csvfile 23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all csv files\n",
    "files = []\n",
    "for i in range(len(sensors)*len(months)):\n",
    "        print(f'Reading csvfile {i}')\n",
    "        df1 = pd.read_csv(file1[i], parse_dates=['date'])\n",
    "        df2 = pd.read_csv(file2[i], parse_dates=['date'])\n",
    "        df3 = pd.read_csv(file3[i], parse_dates=['date'])\n",
    "        df4 = pd.read_csv(file4[i], parse_dates=['date'])\n",
    "        df5 = pd.read_csv(file5[i], parse_dates=['date'])\n",
    "        dfa = [df1,df2,df3,df4,df5]\n",
    "        files.append(dfa)\n",
    "        \n",
    "dfx = pd.DataFrame(files) \n",
    "dfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 00:45:02.362204\n",
      "\n",
      "0 days 00:45:02.362204\n",
      "\n",
      "0 days 00:45:02.362204\n",
      "\n",
      "0 days 00:45:02.362204\n",
      "\n",
      "0 days 00:45:02.362204\n",
      "\n",
      "0 days 00:45:02.362204\n",
      "\n",
      "0 days 00:45:02.362204\n",
      "\n",
      "0 days 00:45:02.362204\n",
      "\n",
      "0 days 00:45:02.362204\n",
      "\n",
      "0 days 00:45:02.362204\n",
      "\n",
      "0 days 00:45:02.362204\n",
      "\n",
      "0 days 00:45:02.362204\n",
      "\n",
      "0 days 01:09:28.115942\n",
      "\n",
      "0 days 01:09:28.115942\n",
      "\n",
      "0 days 01:10:19.905213\n",
      "\n",
      "0 days 01:10:19.905213\n",
      "\n",
      "0 days 01:10:19.905213\n",
      "\n",
      "0 days 01:10:19.905213\n",
      "\n",
      "0 days 01:10:19.905213\n",
      "\n",
      "0 days 01:10:19.905213\n",
      "\n",
      "0 days 01:10:19.905213\n",
      "\n",
      "0 days 01:10:19.905213\n",
      "\n",
      "0 days 01:10:19.905213\n",
      "\n",
      "0 days 01:10:19.905213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Drop any unwanted columns and analyze the difference in date frequency PER CSV FILE\n",
    "delta_date = []\n",
    "for i in range(len(sensors)*len(months)):    \n",
    "    df1_diff = dfx[0][i].assign(diff=dfx[0][i].groupby('latitude')['date'].diff()).dropna()\n",
    "    delta_date.append(np.mean(df1_diff[\"diff\"]))\n",
    "\n",
    "    df2_diff = dfx[1][i].assign(diff=dfx[1][i].groupby('latitude')['date'].diff()).dropna()\n",
    "    delta_date.append(np.mean(df2_diff[\"diff\"]))\n",
    "\n",
    "    df3_diff = dfx[2][i].assign(diff=dfx[2][i].groupby('latitude')['date'].diff()).dropna()\n",
    "    delta_date.append(np.mean(df3_diff[\"diff\"]))\n",
    "\n",
    "    df4_diff = dfx[3][i].assign(diff=dfx[3][i].groupby('latitude')['date'].diff()).dropna()\n",
    "    delta_date.append(np.mean(df4_diff[\"diff\"]))\n",
    "\n",
    "    df5_diff = dfx[4][i].assign(diff=dfx[4][i].groupby('latitude')['date'].diff()).dropna()\n",
    "    delta_date.append(np.mean(df5_diff[\"diff\"]))\n",
    "\n",
    "    print(max(delta_date))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting cleaned csvfile 0\n",
      "Exporting cleaned csvfile 1\n",
      "Exporting cleaned csvfile 2\n",
      "Exporting cleaned csvfile 3\n",
      "Exporting cleaned csvfile 4\n",
      "Exporting cleaned csvfile 5\n",
      "Exporting cleaned csvfile 6\n",
      "Exporting cleaned csvfile 7\n",
      "Exporting cleaned csvfile 8\n",
      "Exporting cleaned csvfile 9\n",
      "Exporting cleaned csvfile 10\n",
      "Exporting cleaned csvfile 11\n",
      "Exporting cleaned csvfile 12\n",
      "Exporting cleaned csvfile 13\n",
      "Exporting cleaned csvfile 14\n",
      "Exporting cleaned csvfile 15\n",
      "Exporting cleaned csvfile 16\n",
      "Exporting cleaned csvfile 17\n",
      "Exporting cleaned csvfile 18\n",
      "Exporting cleaned csvfile 19\n",
      "Exporting cleaned csvfile 20\n",
      "Exporting cleaned csvfile 21\n",
      "Exporting cleaned csvfile 22\n",
      "Exporting cleaned csvfile 23\n"
     ]
    }
   ],
   "source": [
    "# Merge all the dataframes into one complete using concat function then export to CSV\n",
    "c = 0\n",
    "for i in range(len(sensors)):\n",
    "    for j in range(len(months)):\n",
    "        print(f'Exporting cleaned csvfile {c}')\n",
    "        df_all = [dfx[0][c],dfx[1][c],dfx[2][c],dfx[3][c],dfx[4][c]]\n",
    "        df = pd.concat(df_all, join='outer', axis=1).dropna()\n",
    "        df = df.loc[:,~df.columns.duplicated()]\n",
    "        df_clean = df[['sensor','date', 'latitude', 'longitude',\n",
    "           'air_pressure(mBar)', 'air_temperature',   'sea_water_practical_salinity', 'sea_water_temperature', 'wind_speed']]\n",
    "\n",
    "        #Set the file path to export city data\n",
    "        csvFile = os.path.join(\"../data/2017\",f\"{sensors[i]}-{monthsf[j]}.csv\")\n",
    "\n",
    "        #Export clean datframe to csv file\n",
    "        df_clean.to_csv(csvFile)\n",
    "        \n",
    "        #Increment counter by 1\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
